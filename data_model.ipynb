{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relational Data Modelling for Cassandra Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data from CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating list of file paths to process event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.getcwd() + \"/event_data\"\n",
    "\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    file_path_list = glob.glob(os.path.join(root, \"*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data from event files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8056\n"
     ]
    }
   ],
   "source": [
    "# Initiate an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = []\n",
    "\n",
    "# Loop thru every filepath in the file path list\n",
    "\n",
    "for f in file_path_list:\n",
    "\n",
    "    # Read CSV File\n",
    "    with open(f, \"r\", encoding='utf8', newline=\"\") as csvfile:\n",
    "        \n",
    "        # Create new csv reader object\n",
    "        csv_reader = csv.reader(csvfile)\n",
    "        next(csv_reader)\n",
    "    \n",
    "        # Extract Data row by row and append to the list\n",
    "        for row in csv_reader:\n",
    "            full_data_rows_list.append(row)\n",
    "\n",
    "# Print length of data list   \n",
    "print(len(full_data_rows_list))\n",
    "\n",
    "# Print actual data list\n",
    "#print(full_data_rows_list[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Logged In', 'Walter', 'M', '0', 'Frye', '', 'free', 'San Francisco-Oakland-Hayward, CA', 'GET', 'Home', '1.54092E+12', '38', '', '200', '1.54111E+12', '39']\n"
     ]
    }
   ],
   "source": [
    "print(full_data_rows_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load extracted data into single csv file to be used to load Cassanda DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.register_dialect(\"my_dialect\", quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open(\"event_data.csv\", 'w', encoding='utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='my_dialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    \n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        \n",
    "        #Columns to be used are specified in the index\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_data.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Cassandra Provisioning and Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The event_datafile.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=orange>**event_data.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Cluster and Connect to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cassandra DB Cluster Successfully Connected!!!\n"
     ]
    }
   ],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "\n",
    "try:\n",
    "    cluster = Cluster(['localhost'])  # Use the Cassandra container's IP address\n",
    "    session = cluster.connect()\n",
    "    print(\"Cassandra DB Cluster Successfully Connected!!!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create KeySpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyspace Created Successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    session.execute(\"\"\"CREATE KEYSPACE IF NOT EXISTS sparkify WITH REPLICATION = {'class': 'SimpleStrategy', 'replication_factor': 1 }\"\"\")\n",
    "    print(\"Keyspace Created Successfully\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparkify Keyspace set up successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    session.set_keyspace(\"sparkify\")\n",
    "    print(\"Sparkify Keyspace set up successfully\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cassandra DB Query Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query #1\n",
    "\n",
    "#### Give me the artist, song title and song's length in the database where the sessionId = 338, and itemInSession = 4\n",
    "\n",
    "To answer this question we will need to obtain (select) the artist name, song name, and song length from out table, and we will need to filter by sessionId and itemInSession.\n",
    "In CQL our query looks like:\n",
    "\n",
    "*SELECT artist, song_title, song_length FROM session_songs WHERE sessionId = 338 AND itemInSession = 4*\n",
    "\n",
    "- We will name our table **session_songs**\n",
    "- Our primary key will consist of partition key sessionId, and clustering key itemInSession so that we can filter by this attributes later on.\n",
    "- The columns of our table will be: sessionId, itemInSession, artist, song_title and song_length.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Created Successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS session_songs\n",
    "    (sessionId int, itemInSession int, artist text, song_title text, song_length float,\n",
    "    PRIMARY KEY(sessionId, itemInSession))\n",
    "    \"\"\")\n",
    "    print(\"Table Created Successfully\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert Data into DB Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_data.csv'\n",
    "\n",
    "with open(file, encoding='utf-8') as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    next(csv_reader)\n",
    "\n",
    "    for row in csv_reader:\n",
    "        query = \"INSERT INTO session_songs (sessionId, itemInSession, artist, song_title, song_length)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s)\"\n",
    "        \n",
    "        # Extracts columns from CSV file and attaches them to variables\n",
    "        artist_name, user_name, gender, itemInSession, user_last_name, length, level, location, sessionId, song, userId = row\n",
    "        session.execute(query, (int(sessionId), int(itemInSession), artist_name, song, float(length)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify that Data is in DB Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sessionid  iteminsession              artist  song_length  \\\n",
      "0         23              0      Regina Spektor   191.085266   \n",
      "1         23              1     Octopus Project   250.957916   \n",
      "2         23              2      Tegan And Sara   180.061584   \n",
      "3         23              3          Dragonette   153.390564   \n",
      "4         23              4  Lil Wayne / Eminem   229.589752   \n",
      "\n",
      "                          song_title  \n",
      "0    The Calculation (Album Version)  \n",
      "1  All Of The Champs That Ever Lived  \n",
      "2                         So Jealous  \n",
      "3                       Okay Dolores  \n",
      "4                     Drop The World  \n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM session_songs\"\n",
    "result = session.execute(query)\n",
    "\n",
    "# Convert the result to a Pandas DataFrame\n",
    "df = pd.DataFrame(result)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithless Music Matters (Mark Knight Dub) 495.30731201171875\n"
     ]
    }
   ],
   "source": [
    "rows = session.execute(\"\"\"SELECT artist, song_title, song_length FROM session_songs WHERE sessionId = 338 AND itemInSession = 4\"\"\")\n",
    "\n",
    "for row in rows:\n",
    "    print(row.artist, row.song_title, row.song_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "\n",
    "To answer this question we will need to obtain (select) the artist name, song name, user name and user lastname from out table, we will need to filter by userId and sessionId, and order by itemInSession. \n",
    "\n",
    "In CQL our query looks like:\n",
    "\n",
    "*SELECT itemInSession, artist, song, firstName, lastName FROM user_songs WHERE userId = 10 AND sessionId = 182*\n",
    "\n",
    "- We will name our table **user_songs**\n",
    "- Our primary key will consist of composite partition key userId, sessionId. The reason for this is that if we only use userId as partition key, the sessionid which belongs to the same user will be put into different nodes, which will have the performance issue when the volume of data is large.\n",
    "- Our clustering key will be itemInSession so that our results are order by it.\n",
    "- The columns of our table will be: userId, sessionId, itemInSession, artist, song and firstName and lastName."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Created Successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS user_songs\n",
    "    (userId int, sessionId int, artist text, song text, firstName text, lastName text, itemInSession int,\n",
    "    PRIMARY KEY((userId, sessionId), itemInSession))\n",
    "    \"\"\")\n",
    "    print(\"Table Created Successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert Data into DB Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_data.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    next(csv_reader) \n",
    "    for row in csv_reader:\n",
    "        query = \"INSERT INTO user_songs (userId, sessionId, artist, song, firstName, lastName, itemInSession)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        \n",
    "        # Extracts columns from CSV file and attaches them to variables\n",
    "        artist, firstName, gender, itemInSession, lastName, length, level, location, sessionId, song, userId = row\n",
    "        session.execute(query, (int(userId), int(sessionId), artist, song, firstName, lastName, int(itemInSession)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify that Data is in DB Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userid  sessionid  iteminsession                 artist firstname lastname  \\\n",
      "0      58        768              0       System of a Down     Emily   Benson   \n",
      "1      58        768              1  Ghostland Observatory     Emily   Benson   \n",
      "2      58        768              2      Evergreen Terrace     Emily   Benson   \n",
      "3      85        776              2               Deftones   Kinsley    Young   \n",
      "4      85        776              3   The Notorious B.I.G.   Kinsley    Young   \n",
      "\n",
      "                            song  \n",
      "0                     Sad Statue  \n",
      "1                 Stranger Lover  \n",
      "2                           Zero  \n",
      "3           Head Up (LP Version)  \n",
      "4  Playa Hater (Amended Version)  \n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM user_songs\"\n",
    "result = session.execute(query)\n",
    "\n",
    "# Convert the result to a Pandas DataFrame\n",
    "df = pd.DataFrame(result)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Down To The Bone Keep On Keepin' On Sylvie Cruz\n",
      "1 Three Drives Greece 2000 Sylvie Cruz\n",
      "2 Sebastien Tellier Kilometer Sylvie Cruz\n",
      "3 Lonnie Gordon Catch You Baby (Steve Pitron & Max Sanna Radio Edit) Sylvie Cruz\n"
     ]
    }
   ],
   "source": [
    "rows = session.execute(\"\"\"SELECT itemInSession, artist, song, firstName, lastName FROM user_songs WHERE userId = 10 AND sessionId = 182\"\"\")\n",
    "\n",
    "for row in rows:\n",
    "    print(row.iteminsession, row.artist, row.song, row.firstname, row.lastname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "To answer this question we will need to obtain (select) the user first name and lastname from out table, and we will need to filter by song name. As user name and lastname, in large datasets, are not unique, we will add the column userId to uniquely identify users.\n",
    "\n",
    "In CQL our query looks like:\n",
    "\n",
    "*SELECT firstName, lastName FROM app_history WHERE song = 'All Hands Against His Own'*\n",
    "\n",
    "- We will name our table **app_history**\n",
    "- Our primary key will consist of partition key song, and clustering key userId. This uniquely identifies our rows.\n",
    "- The columns of our table will be: song, firstName, lastName and userId."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Created Successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS app_history\n",
    "    (song text, firstName text, lastName text, userId int,\n",
    "    PRIMARY KEY(song, userId))\n",
    "    \"\"\")\n",
    "    print(\"Table Created Successfully\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert Data into DB Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_data.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    next(csv_reader) # skip header\n",
    "    for line in csv_reader:\n",
    "        query = \"INSERT INTO app_history (song, firstName, lastName, userId)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s)\"\n",
    "        artist, firstName, gender, itemInSession, lastName, length, level, location, sessionId, song, userId = line\n",
    "        session.execute(query, (song, firstName, lastName, int(userId)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify that the Data is in the DB Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  song  userid firstname lastname\n",
      "0                   Wonder What's Next      49     Chloe   Cuevas\n",
      "1                  In The Dragon's Den      49     Chloe   Cuevas\n",
      "2    Too Tough (1994 Digital Remaster)      44    Aleena    Kirby\n",
      "3  Rio De Janeiro Blue (Album Version)      49     Chloe   Cuevas\n",
      "4                             My Place      15      Lily     Koch\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM app_history\"\n",
    "result = session.execute(query)\n",
    "\n",
    "# Convert the result to a Pandas DataFrame\n",
    "df = pd.DataFrame(result)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacqueline Lynch\n",
      "Tegan Levine\n",
      "Sara Johnson\n"
     ]
    }
   ],
   "source": [
    "rows = session.execute(\"\"\"SELECT firstName, lastName FROM app_history WHERE song = 'All Hands Against His Own'\"\"\")\n",
    "\n",
    "for row in rows:\n",
    "    print(row.firstname, row.lastname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Tables and Close Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: `user_songs` dropped successfully\n",
      "Table: `session_songs` dropped successfully\n",
      "Table: `app_history` dropped successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    session.execute(\"\"\"DROP TABLE user_songs\"\"\")\n",
    "    print(\"Table: `user_songs` dropped successfully\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    session.execute(\"\"\"DROP TABLE session_songs\"\"\")\n",
    "    print(\"Table: `session_songs` dropped successfully\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    session.execute(\"\"\"DROP TABLE app_history\"\"\")\n",
    "    print(\"Table: `app_history` dropped successfully\")\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apache Cassandra DB Session Shut Down Successful\n",
      "Apache Cassandra DB Cluster Shut Down Successful\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    session.shutdown()\n",
    "    print(\"Apache Cassandra DB Session Shut Down Successful\")\n",
    "    cluster.shutdown()\n",
    "    print(\"Apache Cassandra DB Cluster Shut Down Successful\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
